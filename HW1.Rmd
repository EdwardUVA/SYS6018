---
title: "SYS6018"
author: "Edward Thompson ejt8b"
date: "8/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Homework #1

#### 1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

+ a. The sample size n is extremely large, and the number of predictors p is small.

> In this case a flexible model will be better as it may be able to more easily user higher order terms than an less flexible model like a linear model.

+ b. The number of predictors p is extremely large, and the number of observations n is small.

> When the number of predictors is high it is better to use a less flexible model as a flexible model may chase variations in the predicotrs that may not be useful.  A less flexible model maybe by useful to eliminate colinarity.

+ c. The relationship between the predictors and response is highly non-linear.

> If the relationship is non linear a flexible model is better as it will more easily adjust for the non linear aspects of the model.

+ d. The variance of the error terms, i.e. σ2 = Var(ϵ), is extremely high.

> If Var(ϵ) is high we weill have a high irreducable error.  It is better to use something less flexible as changes in the training set may have large changes in f (pg. 47)

#### 2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction.  Finally, provide n and p.

+ a. We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

> This is a regression problem.  By using profit, employees and industry we should be able to predict salary.  N = 500.  P = 3

+ b. We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables

> Classification problem as we are trying to predict sucess or failure (binary).  N = 20.  P = 13

+ c. We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market

> This is a regression problem.  We are attempting to predict %change Euro/USD.  N = 52 P = 3

#### 6. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?

> The parametric approach assumes a form of the model where as the non parametric does not.  The parametric approach can be used with relativly limted data as only the certain paramters of the form of the model must be calculated.  This model may have some inherent error as it form is fixed and we are best adjusting it to the data we are using to train the model.  

>The nonparametic approach does not make any assumptions to form and is more flexible to take the form of the training data.  As more needs to be calcuated using this method a much larger data set is required.  (pg 36 and 37)

#### 8. This exercise relates to the College data set, which can be found in the file College.csv. It contains a number of variables for 777 different universities and colleges in the US. The variables are:

* Private : Public/private indicator
* Apps : Number of applications received
* Accept : Number of applicants accepted
* Enroll : Number of new students enrolled
* Top10perc : New students from top 10% of high school class
* Top25perc : New students from top 25% of high school class
* F.Undergrad : Number of full-time undergraduates
* P.Undergrad : Number of part-time undergraduates
* Outstate : Out-of-state tuition
* Room.Board : Room and board costs
* Books : Estimated book costs
* Personal : Estimated personal spending
* PhD : Percent of faculty with Ph.D.’s
* Terminal : Percent of faculty with terminal degree
* S.F.Ratio : Student/faculty ratio
* perc.alumni : Percent of alumni who donate
* Expend : Instructional expenditure per student
* Grad.Rate : Graduation rate

+ a. Use the read.csv() function to read the data into R. Call the loaded data college. Make sure that you have the directory set to the correct location for the data.

```{r}
# load our new spiffy tidyverse
library(tidyverse)

#use our load example from this week's tidyverse lesson
#Load the `college` data using the `read_csv()` function (from `readr` package).
library(readr)
College = read_csv('http://faculty.marshall.usc.edu/gareth-james/ISL/College.csv')
# View(College) #pops it up in our environment

#
```

+ b. Look at the data using the fix() function. You should notice that the first column is just the name of each university. We don’t really want R to treat this as data. However, it may be handy to have these names for later. Try the following commands:

```{r}
fix(College)
```

> rownames (college )=college [,1]
> fix (college )

```{r}
rownames(College)=College [,1]
fix(College)
```

You should see that there is now a row.names column with the name of each university recorded. This means that R has given each row a name corresponding to the appropriate university. R will not try to perform calculations on the row names. However, we still need to eliminate the first column in the data where the names are stored. Try

> college =college [,-1]
> fix (college )

```{r}

College=College[,-1]
fix(College)
```

Now you should see that the first data column is Private. Note that another column labeled row.names now appears before the Private column. However, this is not a data column but rather the name that R is giving to each row.

+ c.  
i. Use the summary() function to produce a numerical summary of the variables in the data set.

```{r}
summary(College)
```

ii. Use the pairs() function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix A using A[,1:10].

```{r}
library(GGally)
ggpairs(data = select(.data = College, columns = 1:10))
```

iii. Use the plot() function to produce side-by-side boxplots of Outstate versus Private.

```{r}
ggplot(College, aes(x=factor(Private), y=Outstate)) + geom_boxplot(fill="#E57200", color="#232D4B") + labs(x="Private College", y="Out of State Tuition", title="Boxplot of Private or Public College vs Out of State Tuition")

```

iv. Create a new qualitative variable, called Elite, by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.

> Elite =rep ("No",nrow(college ))
> Elite [college$Top10perc >50]=" Yes"
> Elite =as.factor (Elite)
> college =data.frame(college ,Elite)

```{r}

Elite = rep("No",nrow(College))
Elite[College$Top10perc > 50] = "Yes"
Elite = as.factor(Elite)
College=data.frame(College, Elite)
```

Use the summary() function to see how many elite universities there are. Now use the plot() function to produce side-by-side boxplots of Outstate versus Elite.

```{r}
summary(College)

ggplot(College, aes(x=factor(Elite), y=Outstate)) + geom_boxplot(fill="#E57200", color="#232D4B") + labs(x="Elite", y="Out of State Tuition", title="Boxplot of Elite College vs Out of State Tuition")

```

v. Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables.  You may find the command par(mfrow=c(2,2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.

```{r}
par(mfrow=c(2,2)) #doesn't seem to work in markdown

#all stolen from the Lab with modifications
ggplot(College, aes(x=Apps)) + geom_histogram(bins = 5, fill="#E57200", color="#232D4B") +labs(x="Apps", title="Histogram of Apps vs School, 5 bins")

ggplot(College, aes(x=Apps)) + geom_histogram(bins = 10, fill="#E57200", color="#232D4B") +labs(x="Apps", title="Histogram of Apps vs School, 10 bins")

ggplot(College, aes(x=Apps)) + geom_histogram(bins = 25, fill="#E57200", color="#232D4B") +labs(x="Apps", title="Histogram of Apps vs School, 25 bins")

ggplot(College, aes(x=Apps)) + geom_histogram(bins = 100, fill="#E57200", color="#232D4B") +labs(x="Apps", title="Histogram of Apps vs School, 100 bins")


```


vi. Continue exploring the data, and provide a brief summary of what you discover.

```{r}
plot(College$Apps, College$Accept)
```


#### 10. This exercise involves the Boston housing data set.

(a) To begin, load in the Boston data set. The Boston data set is part of the MASS library in R.

> library (MASS)

Now the data set is contained in the object Boston.
        
> Boston

Read about the data set:

> ?Boston

```{r}
library(MASS)
Boston
# ?Boston
attach(Boston)
```

How many rows are in this data set? How many columns? What do the rows and columns represent?

> There are 506 rows in the dataset.  There are 14 columns.  The columns represent various facts about the Suburbs of Boston, crime rate, if it borders the Charles Reiver, tax value, etc.
  
(b) Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r}
library(GGally)
ggpairs(Boston)
```


(c) Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

> zn, indus, age, rad, ptratio

(d) Do any of the suburbs of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

> is there a better way to look at this?  Its an eye chart

(e) How many of the suburbs in this data set bound the Charles river?

> Does R have a countif function?  This seems to work.

```{r}
# from https://stackoverflow.com/questions/1923273/counting-the-number-of-elements-with-the-values-of-x-in-a-vector
sum(Boston$chas ==1)
```

(f) What is the median pupil-teacher ratio among the towns in this data set?

```{r}

# from https://dplyr.tidyverse.org/reference/summarise.html

summarise(Boston, ave = mean(ptratio))
summarise(Boston, ave = median(ptratio))
```

(g) Which suburb of Boston has lowest median value of owner occupied homes? What are the values of the other predictors for that suburb, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
summarise(Boston, ave = min(medv))
```

> #5 or is that my lowest number?  Do we have a list of names to corelate with?

(h) In this data set, how many of the suburbs average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the suburbs that average more than eight rooms per dwelling.

```{r}
# from https://dplyr.tidyverse.org/reference/filter.html
rm7 = filter(Boston, rm > 7)
rm7
```

```{r}
rm8 = filter(Boston, rm > 8)
rm8
```

```{r}
cm7 = summarise(rm7, ave = median(crim))
cm8 = summarise(rm8, ave = median(crim))
cm7
cm8
```

> The median crime rate is higher when Average number of rooms increases from 7 to 8

  